# NLP - Low-Resource and Multilingual
|Paper|Conference|Remarks
|--|--|--|
|[The State and Fate of Linguistic Diversity and Inclusion in the NLP World](https://arxiv.org/abs/2004.09095)|ACL 2020|1. Investigate the relation between the types of languages, resources, and their representation in NLP conferences to understand the trajectory that different languages have followed over time. 2. Underlines the disparity between languages, especially in terms of their resources, and calls into question the "language agnostic" status of current models and systems.|
|[Cross-lingual learning for text processing: A survey](https://www.sciencedirect.com/science/article/pii/S0957417420305893)|Expert Systems with Applications 2020|1. Identify and analyze four types of cross-lingual transfer based on ‘‘what” is being transferred: label transfer, feature transfer, parameter transfer and representation transfer. 2. Discuss promissing future directions in cross-lingual learning: multilingual datasets, standadization of linguistic resources, pretrained multilingual langauge models, truly low-resourc languages, parameter sharing strategy, curse of multilinguality, combination with multitask learning, word alignment, and machine translation.|
|[A Survey on Recent Approaches for Natural Language Processing in Low-Resource Scenarios](https://arxiv.org/abs/2010.12309)|Arxiv 2020|1. Give an overview of promising approaches for low-resource natural language processing. 2. Examine methods that enable learning when training data is sparse: data augmentation, distant supervision and transfer learning.|

[Back to index](../README.md)

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTEwODYyODYyMzVdfQ==
-->